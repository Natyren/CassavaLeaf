{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze0OTJ0BpizH"
      },
      "source": [
        "!pip install --upgrade efficientnet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5kI1BRL3AN3"
      },
      "source": [
        "!pip install --upgrade albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpzR4tD6NHXI",
        "outputId": "fd8035fd-c1e2-4214-87c8-d5dc608d9656"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('content/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlPOsfiVNL5k"
      },
      "source": [
        "%%time\r\n",
        "!mkdir cassava_leaf\r\n",
        "!unzip /content/content/MyDrive/Cassava_Leaf_Classification/cassava-leaf-disease-classification.zip -d cassava_leaf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgP1XruRp1L7"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional\r\n",
        "import torchvision\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "from torchvision import datasets, transforms, models\r\n",
        "from PIL import Image\r\n",
        "import cv2 as cv\r\n",
        "from efficientnet_pytorch import EfficientNet\r\n",
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "import time\r\n",
        "from tqdm import tqdm\r\n",
        "import copy\r\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, StratifiedKFold\r\n",
        "from sklearn.metrics import f1_score as f1\r\n",
        "from sklearn.metrics import accuracy_score as accuracy\r\n",
        "import json\r\n",
        "import random\r\n",
        "\r\n",
        "from albumentations import (\r\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\r\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\r\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\r\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\r\n",
        "    )\r\n",
        "from albumentations.pytorch import ToTensorV2\r\n",
        "\r\n",
        "from utils import *\r\n",
        "from cutmix import *\r\n",
        "from losses import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6WhCzNLNAlx",
        "outputId": "325460a9-a6cb-4293-9ccc-76875fb29f8d"
      },
      "source": [
        "seed_everything(7)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agcK-IbBNmP6"
      },
      "source": [
        "path = '/content/cassava_leaf/'\r\n",
        "train_data = pd.read_csv(path+'train.csv')\r\n",
        "sub = pd.read_csv(path+'sample_submission.csv')\r\n",
        "train_path = path+'train_images/'\r\n",
        "test_path = path+'test_images/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHadt6EOp3By"
      },
      "source": [
        "class CFG:\r\n",
        "  version = 11\r\n",
        "  img_size = 448\r\n",
        "  N_FOLDS = 4\r\n",
        "  seed = 7\r\n",
        "  epochs = 1 #10 in original\r\n",
        "  batch_size = 16\r\n",
        "  n_workers = 0\r\n",
        "  LR = 0.0001\r\n",
        "  model_name = 'efficientnet-b4'\r\n",
        "\r\n",
        "TRAIN=False #switch to True for training"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlgZhXDJQDhZ"
      },
      "source": [
        "transform_train = {\r\n",
        "    'train': Compose([\r\n",
        "            Resize(CFG.img_size, CFG.img_size),\r\n",
        "            Transpose(p=0.5),\r\n",
        "            HorizontalFlip(p=0.5),\r\n",
        "            VerticalFlip(p=0.5),\r\n",
        "            ShiftScaleRotate(p=0.5),\r\n",
        "            #OpticalDistortion(p=0.5),\r\n",
        "            #GridDistortion(p=0.5),\r\n",
        "            #GaussNoise(var_limit=(10.0, 50.0),p=0.5),\r\n",
        "            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\r\n",
        "            #RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\r\n",
        "            Normalize(mean=[0.4580, 0.5274, 0.3245], std=[0.2267, 0.2285, 0.2170]), #Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\r\n",
        "            #CoarseDropout(max_holes=20, max_height=20, max_width=20, p=0.5),\r\n",
        "            Cutout(num_holes=np.random.randint(20), max_h_size=40, max_w_size=40, p=0.5),\r\n",
        "            ToTensorV2(p=1.0),\r\n",
        "        ], p=1.)\r\n",
        "  ,\r\n",
        "    'val': Compose([\r\n",
        "            Resize(CFG.img_size, CFG.img_size),\r\n",
        "            HorizontalFlip(p=0.5),\r\n",
        "            VerticalFlip(p=0.5),\r\n",
        "            ShiftScaleRotate(p=0.5),\r\n",
        "            Normalize(mean=[0.4580, 0.5274, 0.3245], std=[0.2267, 0.2285, 0.2170]), #Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\r\n",
        "            ToTensorV2(p=1.0),\r\n",
        "        ], p=1.),\r\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlLRT2djwK3g"
      },
      "source": [
        "folds = StratifiedKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.seed)\r\n",
        "X = train_data.iloc[:,:-1]\r\n",
        "y =  train_data.iloc[:,-1:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8z2lia1wLXL"
      },
      "source": [
        "if TRAIN:\r\n",
        "    for fold, (train_idx, val_idx) in enumerate(folds.split(X, y)):\r\n",
        "        print(\"Fold {}/{}\".format(fold + 1, CFG.N_FOLDS))\r\n",
        "\r\n",
        "        model = EfficientNet.from_pretrained(CFG.model_name, num_classes=5) \r\n",
        "        model.to(device)\r\n",
        "        valid = train_data.iloc[val_idx]\r\n",
        "        valid.reset_index(drop=True, inplace=True)\r\n",
        "\r\n",
        "        train = train_data.iloc[train_idx]\r\n",
        "        train.reset_index(drop=True, inplace=True) \r\n",
        "\r\n",
        "        image_datasets = {'train': Leaf_Dataset(train, transforms = transform_train['train'], split_type='train', train_path = train_path, test_path = test_path),\r\n",
        "                      'val': Leaf_Dataset(valid, transforms = transform_train['val'], split_type='val', train_path = train_path, test_path = test_path)}\r\n",
        "\r\n",
        "        dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=CFG.batch_size,\r\n",
        "                                                 shuffle=True, num_workers=CFG.n_workers)\r\n",
        "                  for x in ['train', 'val']}\r\n",
        "        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\r\n",
        "\r\n",
        "        model.to(device)\r\n",
        "\r\n",
        "\r\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG.LR)\r\n",
        "        criterion = SymmetricCrossEntropy()\r\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=25, T_mult=1, eta_min=0.000001,\r\n",
        "                                                                         last_epoch=-1, verbose=True)\r\n",
        "\r\n",
        "        f1_score, fold_loss, fold_acc = train_val(model, CFG.epochs, fold, dataloaders, criterion, optimizer, scheduler, device)\r\n",
        "\r\n",
        "        print(\"Fold №{} f1_score {}\".format(fold+1, f1_score))\r\n",
        "        print(\"Fold №{} loss {}\".format(fold+1, fold_loss))\r\n",
        "        print(\"Fold №{} ACC {}\".format(fold+1, fold_acc))\r\n",
        "        print()"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}